# first, the covariance matrix for our multi-variate normal
# This determines the correlation of our independent variables
sig <- matrix(c(2, .5, .25, .5, 1, 0, .25, 0, 1), nrow=3)
# Now the variables
predictorVar = mvrnorm(n = N, mu = rep(1,3), Sigma = sig)
# Name the predictor variables
colnames(predictorVar) <- c("X1", "X2", "X3")
x <- predictorVar[,1]
b0 = 1 # per class notes
b1 = 2 # per class notes
b2 = -5 # per class notes
# Create the epsilon function with heteroskedasticity include
h <- function(x)  2 + 0.4*x
epsilon = rnorm(N,0,h(x))
y = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(y, epsilon)
abline(lsfit(y, epsilon))
#abline(b0,b1,col=2)
# Select 100 data points
N <- 100
# Creating independent variables
# first, the covariance matrix for our multi-variate normal
# This determines the correlation of our independent variables
sig <- matrix(c(2, .5, .25, .5, 1, 0, .25, 0, 1), nrow=3)
# Now the variables
predictorVar = mvrnorm(n = N, mu = rep(1,3), Sigma = sig)
# Name the predictor variables
colnames(predictorVar) <- c("X1", "X2", "X3")
x <- predictorVar[,1]
b0 = 1 # per class notes
b1 = 2 # per class notes
b2 = -5 # per class notes
# Create the epsilon function with heteroskedasticity include
h <- function(x)  2 + 0.4*x
epsilon = rnorm(N,0,h(x))
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
abline(lsfit(predictedVal, epsilon))
#abline(b0,b1,col=2)
# Set a seed for repeatable results
set.seed(123456)
# Select 100 data points
N <- 100
# Creating independent variables
# first, the covariance matrix for our multi-variate normal
# This determines the correlation of our independent variables
sig <- matrix(c(2, .5, .25, .5, 1, 0, .25, 0, 1), nrow=3)
# Now the variables
predictorVar = mvrnorm(n = N, mu = rep(1,3), Sigma = sig)
# Name the predictor variables
colnames(predictorVar) <- c("X1", "X2", "X3")
x <- predictorVar[,1]
b0 = 1 # per class notes
b1 = 2 # per class notes
b2 = -5 # per class notes
# Create the epsilon function with heteroskedasticity include
h <- function(x)  2 + 10*x
epsilon = rnorm(N,0,h(x))
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
abline(lsfit(predictedVal, epsilon))
#abline(b0,b1,col=2)
library(MASS)
library(lmtest)
library(gvlma) # global validation of linear model assumptions)
# Set a seed for repeatable results
set.seed(123456)
# Select 100 data points
N <- 100
# Creating independent variables
# first, the covariance matrix for our multi-variate normal
# This determines the correlation of our independent variables
sig <- matrix(c(2, .5, .25, .5, 1, 0, .25, 0, 1), nrow=3)
# Now the variables
predictorVar = mvrnorm(n = N, mu = rep(1,3), Sigma = sig)
# Name the predictor variables
colnames(predictorVar) <- c("X1", "X2", "X3")
x <- predictorVar[,1]
b0 = 1 # per class notes
b1 = 2 # per class notes
b2 = -5 # per class notes
# Create the epsilon function with heteroskedasticity include
h <- function(x)  0.5 + 0.1*x
epsilon = rnorm(N,0,h(x))
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
abline(lsfit(predictedVal, epsilon))
#abline(b0,b1,col=2)
# Set a seed for repeatable results
set.seed(123456)
# Select 100 data points
N <- 100
# Creating independent variables
# first, the covariance matrix for our multi-variate normal
# This determines the correlation of our independent variables
sig <- matrix(c(2, .5, .25, .5, 1, 0, .25, 0, 1), nrow=3)
# Now the variables
predictorVar = mvrnorm(n = N, mu = rep(1,3), Sigma = sig)
# Name the predictor variables
colnames(predictorVar) <- c("X1", "X2", "X3")
b0 = 1 # per class notes
b1 = 2 # per class notes
b2 = -5 # per class notes
# Create the epsilon function with heteroskedasticity include
h <- function(x)  0.5 + 0.1*predictorVar[,1]*predictorVar[,2]
epsilon = rnorm(N,0,h(x))
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
abline(lsfit(predictedVal, epsilon))
#abline(b0,b1,col=2)
# Set a seed for repeatable results
set.seed(123456)
# Select 100 data points
N <- 100
# Creating independent variables
# first, the covariance matrix for our multi-variate normal
# This determines the correlation of our independent variables
sig <- matrix(c(2, .5, .25, .5, 1, 0, .25, 0, 1), nrow=3)
# Now the variables
predictorVar = mvrnorm(n = N, mu = rep(1,3), Sigma = sig)
# Name the predictor variables
colnames(predictorVar) <- c("X1", "X2", "X3")
b0 = 1 # per class notes
b1 = 2 # per class notes
b2 = -5 # per class notes
# Create the epsilon function with heteroskedasticity include
h <- function(x)  0.5 + 0.5*predictorVar[,1]*predictorVar[,2]
epsilon = rnorm(N,0,h(x))
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
abline(lsfit(predictedVal, epsilon))
#abline(b0,b1,col=2)
head(predictorVar)
model1 <- p <- lm(predictedVal ~ X1 + X2 , data = predictorVal)
model1 <- p <- lm(predictedVal ~ X1 + X2 , data = predictorVar)
predictorVar = as.data.frame(mvrnorm(n = N, mu = rep(1,3), Sigma = sig))
# Now the variables
predictorVar = as.data.frame(mvrnorm(n = N, mu = rep(1,3), Sigma = sig))
# Name the predictor variables
colnames(predictorVar) <- c("X1", "X2", "X3")
b0 = 1 # per class notes
b1 = 2 # per class notes
b2 = -5 # per class notes
# Create the epsilon function with heteroskedasticity include
h <- function(x)  0.5 + 0.5*predictorVar[,1]*predictorVar[,2]
epsilon = rnorm(N,0,h(x))
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
abline(lsfit(predictedVal, epsilon))
#abline(b0,b1,col=2)
model1 <- p <- lm(predictedVal ~ X1 + X2 , data = predictorVar)
# Select 100 data points
N <- 100
# Creating independent variables
# first, the covariance matrix for our multi-variate normal
# This determines the correlation of our independent variables
sig <- matrix(c(2, .5, .25, .5, 1, 0, .25, 0, 1), nrow=3)
# Now the variables
predictorVar = as.data.frame(mvrnorm(n = N, mu = rep(1,3), Sigma = sig))
# Name the predictor variables
colnames(predictorVar) <- c("X1", "X2", "X3")
b0 = 1 # per class notes
b1 = 2 # per class notes
b2 = -5 # per class notes
# Create the epsilon function with heteroskedasticity include
h <- function(x)  1.0 + 0.4*predictorVar[,1]*predictorVar[,2]
epsilon = rnorm(N,0,h(x))
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
abline(lsfit(predictedVal, epsilon))
#abline(b0,b1,col=2)
model1 <- p <- lm(predictedVal ~ X1 + X2 , data = predictorVar)
model1
# Select number of data points
N <- 500
# Creating independent variables
# first, the covariance matrix for our multi-variate normal
# This determines the correlation of our independent variables
sig <- matrix(c(2, .5, .25, .5, 1, 0, .25, 0, 1), nrow=3)
# Now the variables
predictorVar = as.data.frame(mvrnorm(n = N, mu = rep(1,3), Sigma = sig))
# Name the predictor variables
colnames(predictorVar) <- c("X1", "X2", "X3")
b0 = 1 # per class notes
b1 = 2 # per class notes
b2 = -5 # per class notes
# Create the epsilon function with heteroskedasticity include
h <- function(x)  1.0 + 0.4*predictorVar[,1]*predictorVar[,2]
epsilon = rnorm(N,0,h(x))
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
abline(lsfit(predictedVal, epsilon))
#abline(b0,b1,col=2)
model1 <- p <- lm(predictedVal ~ X1 + X2 , data = predictorVar)
# Select number of data points
N <- 100
# Creating independent variables
# first, the covariance matrix for our multi-variate normal
# This determines the correlation of our independent variables
sig <- matrix(c(2, .5, .25, .5, 1, 0, .25, 0, 1), nrow=3)
# Now the variables
predictorVar = as.data.frame(mvrnorm(n = N, mu = rep(1,3), Sigma = sig))
# Name the predictor variables
colnames(predictorVar) <- c("X1", "X2", "X3")
b0 = 1 # per class notes
b1 = 2 # per class notes
b2 = -5 # per class notes
# Create the epsilon function with heteroskedasticity include
h <- function(x)  1.0 + 0.4*predictorVar[,1]*predictorVar[,2]
epsilon = rnorm(N,0,h(x))
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
abline(lsfit(predictedVal, epsilon))
#abline(b0,b1,col=2)
# Select number of data points
N <- 100
# Creating independent variables
# first, the covariance matrix for our multi-variate normal
# This determines the correlation of our independent variables
sig <- matrix(c(2, .5, .25, .5, 1, 0, .25, 0, 1), nrow=3)
# Now the variables
predictorVar = as.data.frame(mvrnorm(n = N, mu = rep(1,3), Sigma = sig))
# Name the predictor variables
colnames(predictorVar) <- c("X1", "X2", "X3")
b0 = 1 # per class notes
b1 = 2 # per class notes
b2 = -5 # per class notes
# Create the epsilon function with heteroskedasticity include
h <- function(x)  1.0 + 0.4*predictorVar[,1]
epsilon = rnorm(N,0,h(x))
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
abline(lsfit(predictedVal, epsilon))
#abline(b0,b1,col=2)
model1 <- p <- lm(predictedVal ~ X1 + X2 , data = predictorVar)
model1
# Set a seed for repeatable results
set.seed(123456)
# Select number of data points
N <- 1000
# Creating independent variables
# first, the covariance matrix for our multi-variate normal
# This determines the correlation of our independent variables
sig <- matrix(c(2, .5, .25, .5, 1, 0, .25, 0, 1), nrow=3)
# Now the variables
predictorVar = as.data.frame(mvrnorm(n = N, mu = rep(1,3), Sigma = sig))
# Name the predictor variables
colnames(predictorVar) <- c("X1", "X2", "X3")
b0 = 1 # per class notes
b1 = 2 # per class notes
b2 = -5 # per class notes
# Create the epsilon function with heteroskedasticity include
h <- function(x)  1.0 + 0.4*predictorVar[,1]
epsilon = rnorm(N,0,h(x))
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
abline(lsfit(predictedVal, epsilon))
#abline(b0,b1,col=2)
model1 <- p <- lm(predictedVal ~ X1 + X2 , data = predictorVar)
# Select number of data points
N <- 500
# Creating independent variables
# first, the covariance matrix for our multi-variate normal
# This determines the correlation of our independent variables
sig <- matrix(c(2, .5, .25, .5, 1, 0, .25, 0, 1), nrow=3)
# Now the variables
predictorVar = as.data.frame(mvrnorm(n = N, mu = rep(1,3), Sigma = sig))
# Name the predictor variables
colnames(predictorVar) <- c("X1", "X2", "X3")
b0 = 1 # per class notes
b1 = 2 # per class notes
b2 = -5 # per class notes
# Create the epsilon function with heteroskedasticity include
h <- function(x)  1.0 + 0.4*predictorVar[,1]
epsilon = rnorm(N,0,h(x))
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
abline(lsfit(predictedVal, epsilon))
#abline(b0,b1,col=2)
model1 <- p <- lm(predictedVal ~ X1 + X2 , data = predictorVar)
# Select number of data points
N <- 200
# Creating independent variables
# first, the covariance matrix for our multi-variate normal
# This determines the correlation of our independent variables
sig <- matrix(c(2, .5, .25, .5, 1, 0, .25, 0, 1), nrow=3)
# Now the variables
predictorVar = as.data.frame(mvrnorm(n = N, mu = rep(1,3), Sigma = sig))
# Name the predictor variables
colnames(predictorVar) <- c("X1", "X2", "X3")
b0 = 1 # per class notes
b1 = 2 # per class notes
b2 = -5 # per class notes
# Create the epsilon function with heteroskedasticity include
h <- function(x)  1.0 + 0.4*predictorVar[,1]
epsilon = rnorm(N,0,h(x))
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
abline(lsfit(predictedVal, epsilon))
#abline(b0,b1,col=2)
model1 <- p <- lm(predictedVal ~ X1 + X2 , data = predictorVar)
abline(lsfit(predictedVal, epsilon), color = "red")
?abline
abline(lsfit(predictedVal, epsilon), col = "red")
bootReg <- function(formula, data, indices){
d<- data[indices,]
fit <- lm(formula, data = d)
return(coef(fit))
}
bootReg <- function(formula, data, indices){
d<- data[indices,]
fit <- lm(formula, data = d)
return(coef(fit))
}
bootResults <- boot(statistic = bootReg, formula =  predictedVal ~ predictorVar[,1] + predictorVar[,2], data = predictorVar, R = 2000)
library(boot)
bootResults <- boot(statistic = bootReg, formula =  predictedVal ~ predictorVar[,1] + predictorVar[,2], data = predictorVar, R = 2000)
bootResults
summary(bootResults)
bptest(model1)
# Set a seed for repeatable results
set.seed(123456)
# Select number of data points
N <- 200
# Creating independent variables
# first, the covariance matrix for our multi-variate normal
# This determines the correlation of our independent variables
sig <- matrix(c(2, .5, .25, .5, 1, 0, .25, 0, 1), nrow=3)
# Now the variables
predictorVar = as.data.frame(mvrnorm(n = N, mu = rep(1,3), Sigma = sig))
# Name the predictor variables
colnames(predictorVar) <- c("X1", "X2", "X3")
b0 = 1 # per class notes
b1 = 2 # per class notes
b2 = -5 # per class notes
# Create the epsilon function with heteroskedasticity include
h <- function(x)  1.0 + 0.4*predictorVar[,1]
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + h
library(MASS)
library(lmtest)
library(gvlma) # global validation of linear model assumptions)
# Set a seed for repeatable results
set.seed(123456)
# Select number of data points
N <- 200
# Creating independent variables
# first, the covariance matrix for our multi-variate normal
# This determines the correlation of our independent variables
sig <- matrix(c(2, .5, .25, .5, 1, 0, .25, 0, 1), nrow=3)
# Now the variables
predictorVar = as.data.frame(mvrnorm(n = N, mu = rep(1,3), Sigma = sig))
# Name the predictor variables
colnames(predictorVar) <- c("X1", "X2", "X3")
b0 = 1 # per class notes
b1 = 2 # per class notes
b2 = -5 # per class notes
# Create the epsilon function with heteroskedasticity include
h <- function(x)  1.0 + 0.4*predictorVar[,1]
epsilon = rnorm(N,0,h(x))
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
abline(lsfit(predictedVal, epsilon), col = "red")
#abline(b0,b1,col=2)
model1 <- p <- lm(predictedVal ~ X1 + X2 , data = predictorVar)
# Create the epsilon function with heteroskedasticity include
h <- function(x)  1.0 + 0.4*predictorVar[,1]
epsilon = rnorm(N,0,h(x))
epsilon
# Set a seed for repeatable results
set.seed(123456)
# Select number of data points
N <- 100
# Creating independent variables
# first, the covariance matrix for our multi-variate normal
# This determines the correlation of our independent variables
sig <- matrix(c(2, .5, .25, .5, 1, 0, .25, 0, 1), nrow=3)
# Now the variables
predictorVar = as.data.frame(mvrnorm(n = N, mu = rep(1,3), Sigma = sig))
# Name the predictor variables
colnames(predictorVar) <- c("X1", "X2", "X3")
b0 = 1 # per class notes
b1 = 2 # per class notes
b2 = -5 # per class notes
# Create the epsilon function with heteroskedasticity include
h <- function(x)  1.0 + 0.4*predictorVar[,1]
epsilon = rnorm(N,0,h(x))
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
abline(lsfit(predictedVal, epsilon), col = "red")
#abline(b0,b1,col=2)
model1 <- p <- lm(predictedVal ~ X1 + X2 , data = predictorVar)
h <- function(x)  1.0 + 0.4*predictorVar[,1]
epsilon = rnorm(N,0,h(x))
epsilon
# Set a seed for repeatable results
set.seed(123456)
# Select number of data points
N <- 100
# Creating independent variables
# first, the covariance matrix for our multi-variate normal
# This determines the correlation of our independent variables
sig <- matrix(c(2, .5, .25, .5, 1, 0, .25, 0, 1), nrow=3)
# Now the variables
predictorVar = as.data.frame(mvrnorm(n = N, mu = rep(1,3), Sigma = sig))
# Name the predictor variables
colnames(predictorVar) <- c("X1", "X2", "X3")
b0 = 1 # per class notes
b1 = 2 # per class notes
b2 = -5 # per class notes
# Create the epsilon function with heteroskedasticity include
h <- function(x) { 1.0 + 0.4*predictorVar[,2]}
epsilon = rnorm(N,0,h(x))
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
abline(lsfit(predictedVal, epsilon), col = "red")
#abline(b0,b1,col=2)
model1 <- p <- lm(predictedVal ~ X1 + X2 , data = predictorVar)
# test for Heterskedsticity
bptest(model1)
# Create the epsilon function with heteroskedasticity include
h <- function(x) { 1.0 + 0.4*predictorVar[,1]}
epsilon = rnorm(N,0,h(x))
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
abline(lsfit(predictedVal, epsilon), col = "red")
#abline(b0,b1,col=2)
model1 <- p <- lm(predictedVal ~ X1 + X2 , data = predictorVar)
# test for Heterskedsticity
bptest(model1)
# Create the epsilon function with heteroskedasticity include
h <- function(x) { 1.0 + 0.4*predictorVar[,2]}
epsilon = rnorm(N,0,h(x))
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
abline(lsfit(predictedVal, epsilon), col = "red")
#abline(b0,b1,col=2)
model1 <- p <- lm(predictedVal ~ X1 + X2 , data = predictorVar)
# test for Heterskedsticity
bptest(model1)
bootReg <- function(formula, data, indices){
d<- data[indices,]
fit <- lm(formula, data = d)
return(coef(fit))
}
head(predictorVar)
bootResults <- boot(statistic = bootReg, formula =  predictedVal ~ X1 + X2, data = predictorVar, R = 2000)
library(boot)
bootResults <- boot(statistic = bootReg, formula =  predictedVal ~ X1 + X2, data = predictorVar, R = 2000)
bootResults
bootResults <- boot(statistic = bootReg, formula =  predictedVal ~ X1 + X2, data = predictorVar, R = 10000)
bootResults
install.packages("sandwich")
library(sandwich)
## the following commands lead to the same tests:
summary(model1)
coeftest(model1)
coeftest(model1, df = Inf, vcov = vcovHC)
coeftest(fm, df = Inf, vcov = vcovHC(model1, type = "HC0"))
coeftest(model1, df = Inf, vcov = vcovHC(model1, type = "HC0"))
vcovHC(model1, type = "HC")
sandwich_se <- diag(vcovHC(model1, type = "HC"))^0.5
sandwich_se
coef(model1)-1.96*sandwich_se
coeftest(model1, vcov = vcovHC)
coeftest(model1, vcov = vcovHC(model1, type = "HC0"))
set.seed(194812)
n <- 100
x <- rnorm(n)
x
residual_sd <- exp(x)
residual_sd
exp(-0.95755806)
residual_sd*rnorm(n)
0.38382903 * -0.95755806
rnorm(n)
rnorm(n)
epsilon <- exp(predictorVar[,1]) * rnorm(N)
epsilon
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
epsilon <- exp(predictorVar[,1]) * rnorm(N)/100
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
epsilon <- exp(predictorVar[,1]) * rnorm(N)/10
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
epsilon <- exp(predictorVar[,1]) * rnorm(N)/5
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
epsilon <- exp(predictorVar[,1])
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
epsilon <- exp(predictorVar[,1]) * rnorm(N)
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
epsilon <- exp(predictorVar[,1]) * rnorm(N)/100
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
epsilon <- exp(predictorVar[,1]) * rnorm(N)/100
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
# Create the epsilon function with heteroskedasticity include
h <- function(x) { 1.0 + 0.4*predictorVar[,2]}
epsilon = rnorm(N,0,h(x))
#epsilon <- exp(predictorVar[,1]) * rnorm(N)/100
predictedVal = b0 + b1*predictorVar[,1] + b2 * predictorVar[,2] + epsilon
plot(predictedVal, epsilon)
abline(lsfit(predictedVal, epsilon), col = "red")
?rbinom
# Create the epsilon function with heteroskedasticity include
h <- function(x) { 1.0 + 0.4*predictorVar[,2]}
epsilon = suppressWarnings(rnorm(N,0,h(x)))
